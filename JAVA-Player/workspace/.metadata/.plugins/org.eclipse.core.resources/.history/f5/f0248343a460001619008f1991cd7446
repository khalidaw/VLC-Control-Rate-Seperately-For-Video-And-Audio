package editor;

import java.io.FileNotFoundException;
import java.io.PrintWriter;
import java.io.UnsupportedEncodingException;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;

import editor.data.SyncType;

public class MaskCreator {

	static JEvalWrapper jeval = new JEvalWrapper();
	float videoSecondsCounter = 0;
	float audioSecondsCounter = 0;
	List<data> points;

	public enum Command {
		opWait, opRate, opPause, opPlay, opSeek
	}

	public class Operation {
		public Command op;
		public float num;

		public Operation(Command o, float n) {
			op = o;
			num = n;
		}

		public String getOpString() {
			switch (op) {
			case opWait:
				return "sleep";
			case opRate:
				return "rate";
			case opPause:
				// return "rate"; // instead of pausing, we do rate 100
				return "pause";
			case opPlay:
				return "rate";
				// return "play";
			case opSeek:
				return "seek";
			default:
				assert (false);
				return "Unsupported";
			}
		}
	}

	public List<Operation> audioMask = new ArrayList<Operation>();
	public List<Operation> videoMask = new ArrayList<Operation>();

	public MaskCreator(List<data> pList) {
		points = pList;
		doMaskFiles();
		printToFiles();
	}

	void printToFiles() {
		PrintWriter writerAudio = null;
		try {
			writerAudio = new PrintWriter("/home/vlc/simpleMaskAudio", "UTF-8");
		} catch (FileNotFoundException | UnsupportedEncodingException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		PrintWriter writerVideo = null;
		try {
			writerVideo = new PrintWriter("/home/vlc/simpleMaskVideo", "UTF-8");
		} catch (FileNotFoundException | UnsupportedEncodingException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}

		// audio file
		for (Operation p : audioMask) {
			writerAudio.println(p.getOpString() + " " + p.num);
		}

		// video file
		for (Operation p : videoMask) {
			writerVideo.println(p.getOpString() + " " + p.num);
		}

		writerAudio.close();
		writerVideo.close();
	}

	void doMaskFiles() {
		Collections.sort(points);

		/**
		 * Not important, only needed for duration first time
		 */
		data headDummyData = new data();
		headDummyData.startInSeconds = 0;
		points.add(0, headDummyData);

		/** end of dummy point */

		/**
		 * these variables will keep tracking of duration of real movie
		 * according to audio and video
		 */
		float audioInMovie = 0.0f;
		float videoInMovie = 0.0f;
		/** end of tracking duration */
		
		
		
		
//		audioMask.add(new Operation(Command.opWait, pointDuration
//				/ soundRate));
		
		
		
		// TODO 1. add last point to be the last second in video
		// 2. add dummy point as first second (second 0).
		for (int i = 1; i < points.size(); i++) {
			data currentData = points.get(i);
			float dt = currentData.dt;
			float distanceBetweenVideoAudio = 0.f;
			data.SyncType sType = currentData.type;
			float pointDuration = currentData.startInSeconds
					- points.get(i - 1).startInSeconds;
			float prevStartInSec = points.get(i - 1).startInSeconds;
			float soundRate = jeval.getValue(currentData.audioFunc, 0.f);
			float videoRate = jeval.getValue(currentData.videoFunc, 0.f);

			switch (sType) {
			case SyncTypeDontWait:
				audioInMovie += pointDuration;
				break;
			case SyncTypeWait:
				break;
			case SyncTypeDT:
				break;
			default:
				assert (false);
			}

		}
	}
}
